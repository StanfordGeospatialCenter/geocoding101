{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Field Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Locator Geocoding Notebook\n",
    "\n",
    "This Jupyter Notebook provides a workflow for batch geocoding addresses using Stanford's ArcGIS geocoding service, available at [locator.stanford.edu](https://locator.stanford.edu/). The service allows users to submit large numbers of addresses and receive geographic coordinates and related location information in return.\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "The notebook automates the process of submitting address data to the ArcGIS GeocodeAddresses REST API. It reads your input CSV file, processes the addresses in manageable batches, and writes the geocoded results to a new CSV file. The workflow is designed for efficiency and reliability, supporting large datasets and providing progress updates throughout the geocoding job.\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "1. **Set Input Parameters:** Update the input parameters such as the path to your CSV file, output file location, and batch size in the designated cell.\n",
    "2. **Run the Notebook:** Execute the cells in order. The notebook will read your address data, submit it to the geocoding service, and save the results.\n",
    "3. **Monitor Progress:** The notebook prints progress updates and final statistics, so you can track the status of your geocoding job.\n",
    "\n",
    "## Preparing Your Address Table\n",
    "\n",
    "To ensure successful geocoding, your input CSV file must follow the required schema. Each column should match the field names expected by the ArcGIS geocoding service. Refer to the schema in the code block below for the correct column headers and structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary template \n",
    "Your input CSV column headers should conform to the following:\n",
    "```json\n",
    "    arcgis_address_format = {\n",
    "        \"Address\": \"\",\n",
    "        \"Neighborhood\": \"\",\n",
    "        \"City\": \"\",\n",
    "        \"Subregion\": \"\",  # Typically county or equivalent\n",
    "        \"Region\": \"\",  # Typically state or equivalent\n",
    "        \"Postal\": \"\",\n",
    "        \"CountryCode\": \"\"\n",
    "    }\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this do?\n",
    "\n",
    "The **imports section** brings in external Python modules (libraries) that provide extra features for your code. Here’s what each one does:\n",
    "\n",
    "- **csv**  \n",
    "  [csv documentation](https://docs.python.org/3/library/csv.html)  \n",
    "  This is a built-in Python module for reading from and writing to CSV (Comma-Separated Values) files. It helps you handle spreadsheet-like data.\n",
    "\n",
    "- **requests**  \n",
    "  [requests GitHub repo](https://github.com/psf/requests) | [requests documentation](https://requests.readthedocs.io/)  \n",
    "  This is a popular third-party library for making HTTP requests (like GET and POST) to web servers and APIs. In this notebook, it’s used to send address data to the ArcGIS geocoding service and get results back.\n",
    "\n",
    "- **json**  \n",
    "  [json documentation](https://docs.python.org/3/library/json.html)  \n",
    "  This is a built-in Python module for working with JSON (JavaScript Object Notation) data. JSON is a common format for sending data between computers, especially over the web.\n",
    "\n",
    "- **time**  \n",
    "  [time documentation](https://docs.python.org/3/library/time.html)  \n",
    "  This is a built-in Python module for working with time and measuring how long things take. Here, it’s used to track how long the geocoding process takes and estimate how much time is left.\n",
    "\n",
    "---\n",
    "\n",
    "**Tip:**  \n",
    "- Built-in modules like `csv`, `json`, and `time` come with Python, so you don’t need to install anything extra to use them.\n",
    "- Third-party modules like `requests` need to be installed first (usually with `pip install requests`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests # If necessary, install requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv      # For reading and writing CSV files (input addresses and output results)\n",
    "import requests # For making HTTP requests to the ArcGIS geocoding service API\n",
    "import json     # For encoding/decoding data to/from JSON format (used in API requests/responses)\n",
    "import time     # For tracking and reporting elapsed/estimated time during batch geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameters\n",
    "\n",
    "  \n",
    "Below are the input parameters you can adjust to control how the geocoding process works. Each parameter is explained with its purpose, default value, and possible options:\n",
    "\n",
    "- **csv_file_path**  \n",
    "  *Type:* `str`  \n",
    "  *Default:* `'/Users/maples/GitHub/Locator-Scripts/Data/oneMillionAddresses.csv'`  \n",
    "  *Description:* The full path to your input CSV file containing the addresses you want to geocode. Make sure this file exists and follows the required schema.\n",
    "\n",
    "- **output_csv_path**  \n",
    "  *Type:* `str`  \n",
    "  *Default:* `'/Users/maples/GitHub/Locator-Scripts/Data/geocoded_records03.csv'`  \n",
    "  *Description:* The full path (including filename) where the geocoded results will be saved. If the file already exists, new results will be appended.\n",
    "\n",
    "- **arcgis_service_url**  \n",
    "    *Type:* `str`  \n",
    "    *Default:* `'https://locator.stanford.edu/arcgis/rest/services/geocode/USA/GeocodeServer/geocodeAddresses'`  \n",
    "    *Description:* The URL for the ArcGIS geocoding service. You usually do not need to change this unless you are using a different geocoding server.\n",
    "\n",
    "    **Available locator services on [locator.stanford.edu](https://locator.stanford.edu):**\n",
    "    - **Asia Pacific:**  \n",
    "        `https://locator.stanford.edu/arcgis/rest/services/geocode/AsiaPacific/GeocodeServer/geocodeAddresses`\n",
    "    - **Europe:**  \n",
    "        `https://locator.stanford.edu/arcgis/rest/services/geocode/Europe/GeocodeServer/geocodeAddresses`\n",
    "    - **Latin America:**  \n",
    "        `https://locator.stanford.edu/arcgis/rest/services/geocode/LatinAmerica/GeocodeServer/geocodeAddresses`\n",
    "    - **Middle East & Africa:**  \n",
    "        `https://locator.stanford.edu/arcgis/rest/services/geocode/MiddleEastAfrica/GeocodeServer/geocodeAddresses`\n",
    "    - **North America:**  \n",
    "        `https://locator.stanford.edu/arcgis/rest/services/geocode/NorthAmerica/GeocodeServer/geocodeAddresses`\n",
    "    - **USA:**  \n",
    "        `https://locator.stanford.edu/arcgis/rest/services/geocode/USA/GeocodeServer/geocodeAddresses`\n",
    "\n",
    "    Choose the service that best matches your address data region.\n",
    "\n",
    "- **jobSize**  \n",
    "  *Type:* `int` or `'all'`  \n",
    "  *Default:* `10000`  \n",
    "  *Description:* The total number of address records to process.  \n",
    "    - Set to an integer (e.g., `10000`) to process only the first N records.  \n",
    "    - Set to `'all'` (without quotes) to process every record in your input file.\n",
    "\n",
    "- **chunkSize**  \n",
    "  *Type:* `int`  \n",
    "  *Default:* `500`  \n",
    "  *Description:* The number of address records sent to the geocoding service in each batch.  \n",
    "    - The recommended value is between 20 and 1000.  \n",
    "    - Too high a value may cause errors; too low may slow down processing.\n",
    "\n",
    "- **outFields**  \n",
    "  *Type:* `str`  \n",
    "  *Default:* `'*'`  \n",
    "  *Description:* Controls which fields are included in the output.  \n",
    "    - Use `'*'` to include all available output fields.  \n",
    "    - Use `'none'` for minimal output (just latitude and longitude).\n",
    "\n",
    "- **printJob**  \n",
    "  *Type:* `str`  \n",
    "  *Default:* `'yes'`  \n",
    "  *Description:* Whether to print each API request to the console for debugging.  \n",
    "    - Set to `'yes'` to print requests.  \n",
    "    - Set to `'no'` to suppress this output.\n",
    "\n",
    "**Tip:**  \n",
    "If you are new to Python, you can change these values directly in the code cell where they are defined. Make sure to keep the correct data type (e.g., use quotes for text, no quotes for numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '/Users/maples/GitHub/Locator-Scripts/Data/oneMillionAddresses.csv'\n",
    "output_csv_path = '/Users/maples/GitHub/Locator-Scripts/Data/geocoded_records03.csv'\n",
    "arcgis_service_url = 'https://locator.stanford.edu/arcgis/rest/services/geocode/USA/GeocodeServer/geocodeAddresses'\n",
    "jobSize = 10000\n",
    "chunkSize = 500\n",
    "outFields = '*'\n",
    "printJob = 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and submit GET Requests from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `geocode_addresses_batch_rest` function reads your address CSV file, sends the addresses in batches to the ArcGIS geocoding service, and saves the results to a new CSV file. \n",
    "\n",
    "**How it works:**\n",
    "- Reads your input CSV file and splits the addresses into batches (size set by `chunkSize`).\n",
    "- For each batch, sends the addresses to the ArcGIS geocoding service and gets back location results.\n",
    "- Writes the geocoded results to your output CSV file, adding new results as they come in.\n",
    "- Shows progress updates, including how many records are done and how much time is left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_addresses_batch_rest(\n",
    "    csv_file_path,\n",
    "    arcgis_service_url,\n",
    "    output_csv_path,\n",
    "    jobSize,\n",
    "    chunkSize,\n",
    "    outFields,\n",
    "    printJob\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a CSV file to geocode addresses using the ArcGIS Server GeocodeAddresses REST batch endpoint.\n",
    "    Submits up to 1000 records per request.\n",
    "    Appends each chunk to the output CSV so the process can be interrupted and resumed.\n",
    "    Reports final stats at the end.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input CSV file for reading. The file contains address records to be geocoded.\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)  # Reads the CSV into a list of dictionaries (one per row)\n",
    "        addresses = list(reader)\n",
    "        # If jobSize is not 'all', only process up to jobSize records\n",
    "        if jobSize != 'all':\n",
    "            addresses = addresses[:int(jobSize)]\n",
    "\n",
    "    total_records = len(addresses)  # Total number of records to process\n",
    "    start_time = time.time()  # Record the start time for progress reporting\n",
    "\n",
    "    # ArcGIS REST API allows up to 1000 records per batch request.\n",
    "    # chunkSize is set to the minimum of user-specified chunkSize and 1000.\n",
    "    chunkSize = min(int(chunkSize), 1000)\n",
    "    # Split the addresses into batches of chunkSize\n",
    "    batches = [addresses[i:i + chunkSize] for i in range(0, total_records, chunkSize)]\n",
    "\n",
    "    csv_exists = False  # Tracks if the output CSV already exists (to write header only once)\n",
    "    fieldnames = set()  # Collects all field names encountered in the geocoded results\n",
    "    total_processed = 0  # Counter for total processed records\n",
    "\n",
    "    # Iterate over each batch of addresses\n",
    "    for batch_index, batch in enumerate(batches):\n",
    "        # Prepare the records in the format required by the ArcGIS REST API\n",
    "        records = {\n",
    "            \"records\": [\n",
    "                {\n",
    "                    \"attributes\": {\n",
    "                        \"OBJECTID\": idx + batch_index * chunkSize,  # Unique ID for each record\n",
    "                        **{key: record.get(key, \"\") for key in record}  # Include all fields from the input\n",
    "                    }\n",
    "                } for idx, record in enumerate(batch)\n",
    "            ]\n",
    "        }\n",
    "        # Set up the parameters for the POST request to the geocoding service\n",
    "        params = {\n",
    "            'f': 'json',  # Response format\n",
    "            'outFields': outFields,  # Fields to return in the response\n",
    "            'addresses': json.dumps(records)  # The batch of addresses as a JSON string\n",
    "        }\n",
    "\n",
    "        # Optionally print progress for each batch\n",
    "        if printJob.lower() == 'yes':\n",
    "            print(f\"Submitting batch {batch_index+1}/{len(batches)} with {len(batch)} records...\")\n",
    "\n",
    "        try:\n",
    "            # Send the POST request to the ArcGIS geocoding service\n",
    "            response = requests.post(arcgis_service_url, data=params)\n",
    "            response.raise_for_status()  # Raise an error if the request failed\n",
    "            resp_json = response.json()  # Parse the response as JSON\n",
    "        except Exception as e:\n",
    "            # Print error message and skip this batch if the request fails\n",
    "            print(f\"Request failed: {e}\")\n",
    "            print(f\"Response content: {getattr(response, 'text', '')}\")\n",
    "            continue\n",
    "\n",
    "        # Process each geocoded location in the response\n",
    "        batch_records = []\n",
    "        for location in resp_json.get('locations', []):\n",
    "            # Each location should have an 'attributes' dictionary with geocoded data\n",
    "            if isinstance(location.get('attributes'), dict):\n",
    "                batch_records.append(location['attributes'])\n",
    "            else:\n",
    "                print(f\"Warning: Unexpected data format in response: {location}\")\n",
    "\n",
    "        # Update the set of fieldnames with any new fields from this batch\n",
    "        for record in batch_records:\n",
    "            fieldnames.update(record.keys())\n",
    "\n",
    "        # Write the geocoded batch results to the output CSV file\n",
    "        if batch_records:\n",
    "            write_header = not csv_exists  # Write header only for the first batch\n",
    "            with open(output_csv_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=sorted(fieldnames))\n",
    "                if write_header:\n",
    "                    writer.writeheader()\n",
    "                for record in batch_records:\n",
    "                    writer.writerow(record)\n",
    "            csv_exists = True  # Mark that the CSV now exists\n",
    "\n",
    "        # Progress reporting for the user\n",
    "        processed = (batch_index + 1) * chunkSize  # Number of records processed so far\n",
    "        if processed > total_records:\n",
    "            processed = total_records\n",
    "        total_processed += len(batch_records)  # Update total processed count\n",
    "        remaining = total_records - processed  # How many records are left\n",
    "        elapsed_time = time.time() - start_time  # Time elapsed so far\n",
    "        if processed > 0:\n",
    "            # Estimate total and remaining time based on progress so far\n",
    "            estimated_total_time = elapsed_time / processed * total_records\n",
    "            estimated_remaining_time = estimated_total_time - elapsed_time\n",
    "            print(f\"Processed {processed}/{total_records} records. Remaining: {remaining}. Estimated time to finish: {time.strftime('%H:%M:%S', time.gmtime(estimated_remaining_time))}\")\n",
    "\n",
    "    # After all batches are processed, print final statistics\n",
    "    total_time = time.time() - start_time\n",
    "    records_per_hour = (total_processed / total_time) * 3600 if total_time > 0 else 0\n",
    "    print(f\"Geocoded data appended to {output_csv_path}\")\n",
    "    print(f\"Final stats: {total_processed} records processed in {total_time:.2f} seconds ({records_per_hour:.2f} records/hour)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Geocoding Function\n",
    "\n",
    "The next code block actually starts the geocoding process by calling the `geocode_addresses_batch_rest` function.  \n",
    "It uses the parameter values you set earlier in the notebook (like `csv_file_path`, `output_csv_path`, etc.).\n",
    "\n",
    "**How it works:**\n",
    "- When you run the code block, it will read your input CSV file, send the addresses to the ArcGIS geocoding service in batches, and write the results to your output CSV file.\n",
    "- The function uses the current values of the parameter variables. If you change any of these variables in this cell (for example, set a different `chunkSize`), those new values will be used instead of the earlier ones.\n",
    "\n",
    "**Tip:**  \n",
    "You can edit the parameter values directly in this code block to override the settings from the parameter section above. This is useful if you want to quickly test different options without changing the main parameter cell.\n",
    "\n",
    "### Feedback\n",
    "When you run the geocoding function, you’ll see feedback printed directly in the notebook. This feedback includes:\n",
    "\n",
    "- **Batch Submission Updates:**  \n",
    "    For each batch of addresses sent to the geocoding service, the notebook prints which batch is being submitted and how many records it contains.\n",
    "\n",
    "- **Progress Reports:**  \n",
    "    After each batch, you’ll see how many records have been processed, how many remain, and an estimated time to finish based on the current speed.\n",
    "\n",
    "- **Error Messages:**  \n",
    "    If a batch fails to process, an error message will be printed with details to help you troubleshoot.\n",
    "\n",
    "- **Final Statistics:**  \n",
    "    When all batches are complete, the notebook prints a summary showing the total number of records processed, the total time taken, and the average processing speed (records per hour).\n",
    "\n",
    "These messages help you monitor the geocoding job and estimate how long it will take to finish. If you want less feedback, you can set the `printJob` parameter to `'no'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "geocode_addresses_batch_rest(\n",
    "    csv_file_path=csv_file_path,\n",
    "    arcgis_service_url=arcgis_service_url,\n",
    "    output_csv_path=output_csv_path,\n",
    "    jobSize=jobSize,\n",
    "    chunkSize=chunkSize, \n",
    "    outFields=outFields,\n",
    "    printJob=printJob\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
